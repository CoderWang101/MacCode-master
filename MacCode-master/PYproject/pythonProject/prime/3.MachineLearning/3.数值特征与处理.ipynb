{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a6ac431",
   "metadata": {},
   "source": [
    "在机器学习中，数值特征预处理是模型训练前的关键步骤，其核心目标是通过调整数据的尺、分布或补全缺失值，让数据更符合模型的假设（如线性模型假设特征分布相近），从而提升模型的稳定性和性能。\n",
    "- 归一化\n",
    "- 标准化\n",
    "- 缺失值处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d57ec22",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b9885",
   "metadata": {},
   "source": [
    "- 归一化是将特征值缩放到一个固定范围（如[0, 1]），常用方法包括Min-Max缩放和Z-Score标准化。\n",
    "- 归一化的目标是消除特征之间的量纲差异，使模型对特征的影响更加均衡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e96b47d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据: [1. 2. 3. 4. 5.]\n",
      "归一化范围: 0.0 到 1.0\n",
      "归一化后: [0.   0.25 0.5  0.75 1.  ]\n",
      "归一化后的数据类型: float64\n",
      "归一化后的数据形状: (5,)\n",
      "归一化后的数据元素数量: 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 创建示例数据\n",
    "data = np.array([1, 2, 3, 4, 5], dtype=float)\n",
    "\n",
    "# 简单归一化：缩放到 [0, 1]\n",
    "# normalized = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "# 使用MinMaxScaler进行归一化\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))# 归一化范围为[0, 1]; \n",
    "                        #feature_range=(-1, 1)# 归一化范围为[-1, 1]\n",
    "normalized = scaler.fit_transform(data.reshape(-1, 1)).flatten()# 归一化后的数据类型为float64\n",
    "\n",
    "print(\"原始数据:\", data)\n",
    "print(\"归一化范围:\", normalized.min(), \"到\", normalized.max())\n",
    "print(\"归一化后:\", normalized)\n",
    "print(\"归一化后的数据类型:\", normalized.dtype)\n",
    "print(\"归一化后的数据形状:\", normalized.shape)\n",
    "print(\"归一化后的数据元素数量:\", normalized.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80ebd0",
   "metadata": {},
   "source": [
    "归一化的优点:\n",
    "- 归一化后的特征在相同的尺度上，避免了特征之间的量纲问题。\n",
    "- 归一化后的特征在相同的区间内，方便模型的训练和解释。\n",
    "-  归一化处理之后，更容易通过梯度下降法找最优解\n",
    "\n",
    "归一化的缺点:\n",
    "- 归一化容易受到异常点的影响\n",
    "- 归一化处理数据，鲁棒性较差（也就是在异常点的影响下波动较大），只适合精确、数据量小的场景\n",
    "- 归一化会改变原始数据的分布，某些异常值可能会被压缩到正常范围内。\n",
    "- 归一化会丢失原始数据的一些信息，如数据的中心位置和数据的分布形状。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca11d3",
   "metadata": {},
   "source": [
    "# 标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd629d",
   "metadata": {},
   "source": [
    "标准化的核心是将特征转换为均值为0、标准差为1的分布（也就是分布），保留数据的相对离散程度，更适合近似正态分布的数据。\n",
    "标准化也被称力（Z-score缩放）\n",
    "\n",
    "不会破坏数据的自然分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5805a382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据: [1. 2. 3. 4. 5.]\n",
      "标准化后: [[-1.41421356]\n",
      " [-0.70710678]\n",
      " [ 0.        ]\n",
      " [ 0.70710678]\n",
      " [ 1.41421356]]\n",
      "标准化参数: [3.] [1.41421356]\n",
      "方差: [2.]\n",
      "标准差: [1.41421356]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 创建示例数据\n",
    "data = np.array([1, 2, 3, 4, 5], dtype=float)\n",
    "\n",
    "# 简单标准化\n",
    "# 标准化数据：减去均值后除以标准差\n",
    "# mean = np.mean(data)\n",
    "# std = np.std(data)\n",
    "# normalized_data = (data - mean) / std\n",
    "# print(\"原始数据:\", data)\n",
    "# print(\"标准化后:\", normalized_data)\n",
    "\n",
    "# 使用StandardScaler\n",
    "model = StandardScaler()\n",
    "normalized_data = model.fit_transform(data.reshape(-1, 1))\n",
    "\n",
    "print(\"原始数据:\", data)\n",
    "print(\"标准化后:\", normalized_data)\n",
    "print(\"标准化参数:\", model.mean_, model.scale_)\n",
    "print(\"方差:\", model.var_)\n",
    "print(\"标准差:\", model.scale_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304743bb",
   "metadata": {},
   "source": [
    "# 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. 删除缺失值\n",
    "def drop_missing(df: pd.DataFrame, axis: int = 0, how: str = 'any') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    删除缺失值\n",
    "    :param df: 原始数据框\n",
    "    :param axis: 0 删除行，1 删除列\n",
    "    :param how: 'any' 只要存在缺失就删除，'all' 全部缺失才删除\n",
    "    :return: 处理后的数据框\n",
    "    \"\"\"\n",
    "    return df.dropna(axis=axis, how=how)\n",
    "\n",
    "\n",
    "# 2. 均值/中位数/众数填充\n",
    "def fill_with_statistic(df: pd.DataFrame, strategy: str = 'mean') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    用统计量填充数值型缺失值\n",
    "    :param df: 原始数据框\n",
    "    :param strategy: 'mean' 均值，'median' 中位数，'mode' 众数\n",
    "    :return: 处理后的数据框\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.select_dtypes(include=np.number).columns:\n",
    "        if strategy == 'mean':\n",
    "            df_copy[col].fillna(df_copy[col].mean(), inplace=True)\n",
    "        elif strategy == 'median':\n",
    "            df_copy[col].fillna(df_copy[col].median(), inplace=True)\n",
    "        elif strategy == 'mode':\n",
    "            df_copy[col].fillna(df_copy[col].mode()[0], inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# 3. 前向/后向填充\n",
    "def fill_with_ffill_bfill(df: pd.DataFrame, method: str = 'ffill') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    用前向或后向填充缺失值\n",
    "    :param df: 原始数据框\n",
    "    :param method: 'ffill' 前向填充，'bfill' 后向填充\n",
    "    :return: 处理后的数据框\n",
    "    \"\"\"\n",
    "    return df.fillna(method=method)\n",
    "\n",
    "\n",
    "# 4. 常数填充\n",
    "def fill_with_constant(df: pd.DataFrame, fill_value: any) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    用指定常数填充缺失值\n",
    "    :param df: 原始数据框\n",
    "    :param fill_value: 用于填充的常数\n",
    "    :return: 处理后的数据框\n",
    "    \"\"\"\n",
    "    return df.fillna(fill_value)\n",
    "\n",
    "\n",
    "# 5. 插值法填充\n",
    "def fill_with_interpolate(df: pd.DataFrame, method: str = 'linear') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    用插值法填充缺失值\n",
    "    :param df: 原始数据框\n",
    "    :param method: 插值方法，如 'linear', 'polynomial', 'spline' 等\n",
    "    :return: 处理后的数据框\n",
    "    \"\"\"\n",
    "    return df.interpolate(method=method)\n",
    "\n",
    "\n",
    "# 6. KNN填充\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def fill_with_knn(df: pd.DataFrame, n_neighbors: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    用KNN填充缺失值\n",
    "    :param df: 原始数据框\n",
    "    :param n_neighbors: 邻居数量\n",
    "    :return: 处理后的数据框\n",
    "    \"\"\"\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    return pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "\n",
    "# 7. 多重插补（MICE）\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "def fill_with_mice(df: pd.DataFrame, max_iter: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    用多重插补（MICE）填充缺失值\n",
    "    :param df: 原始数据框\n",
    "    :param max_iter: 最大迭代次数\n",
    "    :return: 处理后的数据框\n",
    "    \"\"\"\n",
    "    imputer = IterativeImputer(max_iter=max_iter, random_state=42)\n",
    "    return pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "\n",
    "# 8. 分类变量用特殊值填充\n",
    "def fill_categorical_with_missing(df: pd.DataFrame, fill_value: str = 'Missing') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    对分类变量缺失值用特殊值填充\n",
    "    :param df: 原始数据框\n",
    "    :param fill_value: 用于填充的特殊值\n",
    "    :return: 处理后的数据框\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.select_dtypes(include='object').columns:\n",
    "        df_copy[col].fillna(fill_value, inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# 9. 分组填充（按类别均值填充）\n",
    "def fill_groupby_mean(df: pd.DataFrame, group_cols: list, target_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    按分组均值填充缺失值\n",
    "    :param df: 原始数据框\n",
    "    :param group_cols: 分组列名列表\n",
    "    :param target_col: 需要填充的目标列\n",
    "    :return: 处理后的数据框\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    df_copy[target_col] = df_copy.groupby(group_cols)[target_col].transform(\n",
    "        lambda x: x.fillna(x.mean())\n",
    "    )\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# 10. 模型预测填充（示例：用随机森林）\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def fill_with_model(df: pd.DataFrame, target_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    用模型预测缺失值（以随机森林为例）\n",
    "    :param df: 原始数据框\n",
    "    :param target_col: 需要填充的目标列\n",
    "    :return: 处理后的数据框\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    missing_mask = df_copy[target_col].isnull()\n",
    "    if missing_mask.sum() == 0:\n",
    "        return df_copy\n",
    "\n",
    "    # 分离训练集和预测集\n",
    "    train = df_copy[~missing_mask]\n",
    "    test = df_copy[missing_mask]\n",
    "\n",
    "    # 特征列（排除目标列）\n",
    "    feature_cols = [c for c in df_copy.columns if c != target_col]\n",
    "\n",
    "    # 训练模型\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(train[feature_cols], train[target_col])\n",
    "\n",
    "    # 预测缺失值\n",
    "    predicted = model.predict(test[feature_cols])\n",
    "    df_copy.loc[missing_mask, target_col] = predicted\n",
    "    return df_copy\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
