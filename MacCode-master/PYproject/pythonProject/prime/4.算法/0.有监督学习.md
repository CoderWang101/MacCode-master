# 0.基本概念
有监督学习：使用带标签的数据进行训练，目标是学习从输入到输出的映射。分为分类和回归。
- 分类:标签值必须是**整型数**,且是离散值
- 回归: 目标值必须是**连续型数值**,区间内可分

无监督学习：使用无标签数据，目标是发现数据的内在结构或模式。包括聚类、降维、关联规则等。

分类问题一判断类型
回归问题一获取确定数值

分类流程：
- 1 计算未知样本到每一个训练样本的距离
- 2 将训练样本，根据距离大小升序排列
- 3 取出距离最近的K个训练样本
- 4 进行多数表决，统计 K 个样本中哪个类别的样本个数最多
- 5 将未知的样本归属到出现次数最多的类别

回归流程：
- 1 计算未知样本到每一个训练样本的距离
- 2 将训练样本，根据距离大小升序排列
- 3 取出距离最近的K个训练样本
- 4 把这个 K个样本的目标值计算其平均值
- 5 将上述平均值作为将未知的样本预测的值

## 0.1欠拟合与过拟合
- 欠拟合：模型在训练数据和测试数据上的性能都较差，无法捕捉到数据的真实模式。
- 过拟合：模型在训练数据上的性能非常好，但是在测试数据上的性能却较差，模型过于复杂，对训练数据的噪声和异常值敏感。

怎么判断

- 欠拟合：训练集和验证集都不高，学不明白。
- 过拟合：训练集极高、验证集明显低，只会“背题”。

怎么改

- 欠拟合：换更有表达力的模型（CNN）、做数据增强、训练更充分。
- 过拟合：多数据/强数据增强（翻转、裁剪、颜色扰动）、加正则（Dropout/权重衰减）、早停、把模型简化。

# knn:

优点：
- 1 算法简单，理论成熟，既可以用来做分类，也可以用来做回归
- 2 无显式训练过程（惰性学习），预测阶段需要使用全部训练数据

缺点：
- 1 预测时计算量大，需遍历所有训练样本
- 2 维度灾难，对高维数据敏感工
- 3 K值过小，模型容易受到异常点的影响，有过拟合的问题
- 4 K值过大，模型不易受到异常点的影响，但是可能会存在欠拟合的风险
